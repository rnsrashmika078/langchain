# agent_doc.py
import os
from pathlib import Path
from PyPDF2 import PdfReader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings  # âœ… FIXED

from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from dotenv import load_dotenv

# Load .env file (if present)
load_dotenv()

# 1ï¸âƒ£ Load PDF
def load_pdf(path):
    try:
        reader = PdfReader(path)
        text = "".join(page.extract_text() or "" for page in reader.pages)
        return text
    except Exception as e:
        raise Exception(f"âŒ Failed to read PDF: {e}")

# 2ï¸âƒ£ Get API key (Priority: .env > env var > prompt)
def get_groq_key():
    key = os.getenv("GROQ_API_KEY", "").strip()
    if not key:
        print("âš ï¸  GROQ_API_KEY not found in .env or environment.")
        from getpass import getpass
        key = getpass("ğŸ”‘ Enter your Groq API key: ").strip()
    return key

# === MAIN ===
PDF_PATH = "doc.pdf"
DB_PATH = Path("faiss_index")

# Ensure PDF exists
if not os.path.exists(PDF_PATH):
    print(f"âŒ PDF not found: {PDF_PATH}")
    exit(1)

# Get API key
GROQ_API_KEY = get_groq_key()
if not GROQ_API_KEY:
    print("âŒ No API key provided. Please set GROQ_API_KEY in .env or enter manually.")
    exit(1)

# Load & chunk PDF
print("\nğŸ“„ Loading PDF...")
text = load_pdf(PDF_PATH)

print("âœ‚ï¸  Splitting into chunks...")
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_text(text)
print(f"âœ… Created {len(chunks)} chunks.")

# Embed with HuggingFace (all-MiniLM-L6-v2)
print("ğŸ§  Embedding (first time only)...")
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# Load or create FAISS index
if DB_PATH.exists():
    print("ğŸ“‚ Loading FAISS index from disk...")
    db = FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)
else:
    print("ğŸ’¾ Creating new FAISS index...")
    db = FAISS.from_texts(chunks, embeddings)
    db.save_local(DB_PATH)

# Initialize Groq LLM
print("ğŸš€ Starting Groq LLM (openai/gpt-oss-120b)...")
llm = ChatGroq(model_name="openai/gpt-oss-120b", api_key=GROQ_API_KEY)

# Chat loop
print("\nğŸ’¬ Chatting with your PDF! (Type 'quit' or Ctrl+C to exit)\n")

retriever = db.as_retriever(k=3)

try:
    while True:
        question = input("ğŸ‘¤ You: ").strip()
        if not question:
            continue
        if question.lower() in ["quit", "exit", "q"]:
            print("ğŸ‘‹ Goodbye!")
            break

        # Retrieve top 3 chunks
        docs = retriever.invoke(question)
        context = "\n\n".join(doc.page_content for doc in docs)

        # Simple prompt
        prompt = f"""Use ONLY this context to answer the question. If unsure, say: "I don't know.".

Context:
{context}

Question: {question}
Answer:"""

        # Get response
        response = llm.invoke(prompt)
        print(f"ğŸ¤– Assistant: {response.content}\n")

except KeyboardInterrupt:
    print("\nğŸ‘‹ Goodbye!")
except Exception as e:
    print(f"\nâš ï¸ Error: {e}")
